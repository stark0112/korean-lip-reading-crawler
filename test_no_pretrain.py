# ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ë§Œ í…ŒìŠ¤íŠ¸
# TL48 í•˜ë‚˜ íŒŒì¼ë§Œ ì‚¬ìš©í•´ì„œ ë¹ ë¥´ê²Œ ì‹¤í—˜

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import cv2
import mediapipe as mp
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
import pickle
import time
import random
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
import argparse
import os
import shutil
from datetime import datetime
import pandas as pd
import seaborn as sns

# train.pyì—ì„œ í•„ìš”í•œ í´ë˜ìŠ¤ë“¤ import
from train import (
    Config, LipROIExtractor, KoreanGraphemeProcessor,
    UnlabeledVideoDataset, LabeledVideoDataset, CrawlerVideoDataset,
    VisualFrontend, PositionalEncoding, TemporalEncoder, 
    MaskedVideoModel, LipReadingModel, PretrainTrainer, 
    FinetuneTrainer, ModelEvaluator, collate_fn,
    setup_directories
)

def test_no_pretrain():
    """ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ë§Œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    
    # ì„¤ì •
    config = Config()
    # ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ ì—í¬í¬ ìˆ˜ ì¡°ì •
    config.PRETRAIN_EPOCHS = 10  # 100 -> 10
    config.FINETUNE_EPOCHS = 5   # 50 -> 5
    config.BATCH_SIZE = 2         # 1 -> 2 (BatchNorm ë¬¸ì œ í•´ê²°)
    
    device = config.DEVICE
    print(f"âš™ï¸ ì„¤ì •:")
    print(f"   - ì—í¬í¬: {config.FINETUNE_EPOCHS}")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {config.BATCH_SIZE}")
    print(f"   - ë””ë°”ì´ìŠ¤: {device}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ë°ì´í„° ì¤€ë¹„
    print("\nğŸ“Š ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    
    # TL48ì—ì„œ í•˜ë‚˜ì˜ MP4 íŒŒì¼ê³¼ JSON íŒŒì¼ë§Œ ì‚¬ìš©
    labeled_data_dir = Path("009.ë¦½ë¦¬ë”©(ì…ëª¨ì–‘) ìŒì„±ì¸ì‹ ë°ì´í„°/01.ë°ì´í„°/1.Training/ìì†Œ_ë¼ë²¨ë§ë°ì´í„°")
    source_data_dir = Path("009.ë¦½ë¦¬ë”©(ì…ëª¨ì–‘) ìŒì„±ì¸ì‹ ë°ì´í„°/01.ë°ì´í„°/1.Training/ì›ì²œë°ì´í„°")
    
    tl48_label_dir = labeled_data_dir / "TL48" / "ì†ŒìŒí™˜ê²½1" / "C(ì¼ë°˜ì¸)" / "M(ë‚¨ì„±)" / "M(ë‚¨ì„±)_24"
    ts48_source_dir = source_data_dir / "TS48" / "ì†ŒìŒí™˜ê²½1" / "C(ì¼ë°˜ì¸)" / "M(ë‚¨ì„±)" / "M(ë‚¨ì„±)_24"
    
    # ì²« ë²ˆì§¸ JSON íŒŒì¼ ì°¾ê¸°
    json_files = list(tl48_label_dir.glob("*.json"))
    if not json_files:
        raise FileNotFoundError(f"TL48ì—ì„œ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {tl48_label_dir}")
    
    # ì²« ë²ˆì§¸ JSON íŒŒì¼ê³¼ ëŒ€ì‘í•˜ëŠ” MP4 íŒŒì¼ (ì›ì²œë°ì´í„°ì—ì„œ)
    json_path = json_files[0]
    video_filename = json_path.stem.replace('_jaso', '') + ".mp4"  # _jaso ì œê±°
    video_path = ts48_source_dir / video_filename
    
    if not video_path.exists():
        raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {video_path}")
    
    print(f"ğŸ“Š ì‚¬ìš©í•  ë°ì´í„°:")
    print(f"   - ë¹„ë””ì˜¤: {video_path.name}")
    print(f"   - ë¼ë²¨: {json_path.name}")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    try:
        # JSON íŒŒì¼ êµ¬ì¡° í™•ì¸
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° ì²« ë²ˆì§¸ í•­ëª©ì˜ Sentence_info ì‚¬ìš©
            annotations = data[0]['Sentence_info']
        else:
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° Sentence_info í‚¤ ì‚¬ìš©
            annotations = data.get('Sentence_info', [])
        
        print(f"ğŸ“Š JSON êµ¬ì¡°: {type(data)}, ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {len(annotations)}")
        
        # ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ìƒì„±
        dataset = CustomLabeledDataset(str(video_path), annotations)
        print(f"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {len(dataset)}ê°œ ìƒ˜í”Œ")
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
        raise
    
    # ë°ì´í„° ë¶„í•  (8:2)
    total_samples = len(dataset)
    train_size = int(total_samples * 0.8)
    val_size = total_samples - train_size
    
    # ëœë¤ ë¶„í• 
    indices = list(range(total_samples))
    random.shuffle(indices)
    
    train_indices = indices[:train_size]
    val_indices = indices[train_size:]
    
    # ì„œë¸Œì…‹ ìƒì„±
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    
    print(f"ğŸ“ˆ í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ ìƒ˜í”Œ")
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ ìƒ˜í”Œ")
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=True,
        num_workers=0,  # ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜ í•´ê²°
        collate_fn=collate_fn,
        drop_last=True # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ 1ê°œì¼ ë•Œ ë²„ë¦¬ë„ë¡ ì„¤ì •
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=0,  # ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë¥˜ í•´ê²°
        collate_fn=collate_fn,
        drop_last=True # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ 1ê°œì¼ ë•Œ ë²„ë¦¬ë„ë¡ ì„¤ì •
    )
    
    # ëª¨ë¸ ìƒì„± (ì‚¬ì „í•™ìŠµ ì—†ìŒ)
    print("\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
    model = LipReadingModel(vocab_size=config.VOCAB_SIZE).to(device)
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ—ï¸ ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
    
    # í›ˆë ¨
    print("\nğŸ¯ ë³¸ í›ˆë ¨ ì‹œì‘...")
    trainer = FinetuneTrainer(model, train_loader, val_loader, device)
    trainer.train(epochs=config.FINETUNE_EPOCHS)
    
    # í‰ê°€
    print("\nğŸ” ëª¨ë¸ í‰ê°€ ì¤‘...")
    evaluator = ModelEvaluator(model, device)
    metrics = evaluator.evaluate(val_loader)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“Š ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ ê²°ê³¼")
    print("="*50)
    
    print(f"ğŸ“ˆ í›ˆë ¨ ì™„ë£Œ!")
    print(f"ğŸ“Š í‰ê°€ ê²°ê³¼:")
    print(f"   - GER (ìì†Œ ì˜¤ë¥˜ìœ¨): {metrics['ger']:.4f} ({metrics['ger']*100:.2f}%)")
    print(f"   - CER (ìŒì ˆ ì˜¤ë¥˜ìœ¨): {metrics['cer']:.4f} ({metrics['cer']*100:.2f}%)")
    
    # ëª¨ë¸ ì €ì¥
    save_path = Path("test_results") / "no_pretrain_model.pt"
    save_path.parent.mkdir(exist_ok=True)
    torch.save(model.state_dict(), save_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥: {save_path}")
    
    return metrics

class CustomLabeledDataset(Dataset):
    """ì»¤ìŠ¤í…€ ë¼ë²¨ë§ëœ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ (ìì†Œ ë¼ë²¨ë§ ë°ì´í„°ìš©)"""
    
    def __init__(self, video_path, annotations):
        self.video_path = Path(video_path)
        self.annotations = annotations
        self.lip_extractor = LipROIExtractor()
        self.grapheme_processor = KoreanGraphemeProcessor()
        
        print(f"ğŸ“Š ë¼ë²¨ ë°ì´í„°: {len(self.annotations)}ê°œ ë¬¸ì¥")
    
    def __len__(self):
        return len(self.annotations)
    
    def __getitem__(self, idx):
        annotation = self.annotations[idx]
        
        # ì‹œê°„ êµ¬ê°„ ì •ë³´
        start_time = annotation['start_time']
        end_time = annotation['end_time']
        
        # ìì†Œ ë¼ë²¨ (ì´ë¯¸ ë¶„í•´ëœ ìƒíƒœ)
        sentence_graphemes = annotation['sentence_text']  # ìì†Œ ë¦¬ìŠ¤íŠ¸
        grapheme_indices = []
        
        for grapheme in sentence_graphemes:
            if grapheme in self.grapheme_processor.grapheme_to_idx:
                grapheme_indices.append(self.grapheme_processor.grapheme_to_idx[grapheme])
        
        # ì…ìˆ  ì‹œí€€ìŠ¤ ì¶”ì¶œ
        lip_sequence = self.lip_extractor.extract_video_lip_sequence(
            self.video_path, start_time, end_time
        )
        
        return {
            'frames': torch.FloatTensor(lip_sequence),
            'graphemes': torch.LongTensor(grapheme_indices),
            'frame_length': len(lip_sequence),
            'grapheme_length': len(grapheme_indices),
            'text': ''.join(sentence_graphemes)
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--run', action='store_true', help='í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    if args.run:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        metrics = test_no_pretrain()
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print("ğŸš€ ì‚¬ì „í•™ìŠµ ì—†ì´ ë³¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸")
        print("\nì‚¬ìš©ë²•:")
        print("python test_no_pretrain.py --run")
        print("\nì´ í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:")
        print("1. TL48 í•˜ë‚˜ íŒŒì¼ë§Œ ì‚¬ìš©")
        print("2. ì‚¬ì „í•™ìŠµ ì—†ì´ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í›ˆë ¨")
        print("3. 5 ì—í¬í¬ í›ˆë ¨ í›„ í‰ê°€")
        print("4. ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥")

if __name__ == "__main__":
    main() 